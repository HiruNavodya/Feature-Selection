{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0wMQta7CBqY",
        "outputId": "bcaf7349-55c1-4234-e0e5-ca605021b498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Subset: (('X2', 'X3', 'X4'), 1.2506454789833872)\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# Create a DataFrame\n",
        "data = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
        "data['target'] = iris['target']\n",
        "\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n"
      ],
      "metadata": {
        "id": "19W7jT76CpRN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def best_subset_selection(X, y):\n",
        "    results = []\n",
        "    for k in range(1, len(X.columns) + 1):\n",
        "        for combo in itertools.combinations(X.columns, k):\n",
        "            X_subset = X[list(combo)]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.3, random_state=42)\n",
        "            model = LogisticRegression(max_iter=200).fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "            results.append((combo, accuracy))\n",
        "    best_model = max(results, key=lambda x: x[1])\n",
        "    return best_model\n",
        "\n",
        "best_model = best_subset_selection(X, y)\n",
        "print(\"Best Subset:\", best_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaXxSZJzCqnf",
        "outputId": "ab410e7b-2284-4b58-cb95-aae46c49171f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Subset: (('petal length (cm)',), 1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def forward_selection(X, y):\n",
        "    remaining = list(X.columns)\n",
        "    selected = []\n",
        "    current_score, best_new_score = 0.0, 0.0\n",
        "    while remaining:\n",
        "        scores_with_candidates = []\n",
        "        for candidate in remaining:\n",
        "            X_subset = X[selected + [candidate]]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.3, random_state=42)\n",
        "            model = LinearRegression().fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            score = r2_score(y_test, y_pred)\n",
        "            scores_with_candidates.append((score, candidate))\n",
        "        scores_with_candidates.sort(reverse=True)\n",
        "        best_new_score, best_candidate = scores_with_candidates[0]\n",
        "        if current_score < best_new_score:\n",
        "            remaining.remove(best_candidate)\n",
        "            selected.append(best_candidate)\n",
        "            current_score = best_new_score\n",
        "        else:\n",
        "            break\n",
        "    return selected, current_score\n",
        "\n",
        "selected_features, score = forward_selection(X, y)\n",
        "print(\"Selected features by forward selection:\", selected_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7kZ5iaqCED8",
        "outputId": "884030a5-bbea-44b2-f135-76de01c89e9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features by forward selection: ['petal width (cm)', 'sepal width (cm)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "def backward_elimination(X, y):\n",
        "    X = sm.add_constant(X)  # adding a constant\n",
        "    while len(X.columns) > 1:\n",
        "        model = sm.OLS(y, X).fit()\n",
        "        p_values = model.pvalues\n",
        "        max_p_value = p_values.idxmax()\n",
        "        if p_values[max_p_value] > 0.05:  # If p-value is greater than 0.05, remove the feature\n",
        "            X = X.drop(max_p_value, axis=1)\n",
        "        else:\n",
        "            break\n",
        "    return X.columns\n",
        "\n",
        "selected_features = backward_elimination(X, y)\n",
        "print(\"Selected features by backward elimination:\", selected_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5pGBgFCCEIk",
        "outputId": "b5f7d407-dda4-4b8f-a5eb-fc4f33041146"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features by backward elimination: Index(['sepal length (cm)', 'petal length (cm)', 'petal width (cm)'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YQJXfuSKCELr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E-2QFjtrCEPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1FoWL4gWCESt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAi7c1nkCEWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5yXylfJDCEZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q0VcE5EyCEc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2NAvj-oWCEgf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}